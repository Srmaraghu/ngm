name: District Court Cases Scraper

on:
  schedule:
    # TEMPORARY: Run every 8 hours for backfilling (will revert to daily)
    # Runs at 6:32 AM, 2:32 PM, 10:32 PM UTC (12:17 PM, 8:17 PM, 4:17 AM Nepal Time)
    - cron: '32 6,14,22 * * *'
  workflow_dispatch: # Allow manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    environment: 'NGM Scrape'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: latest
          virtualenvs-create: true
          virtualenvs-in-project: true
      
      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: venv-${{ runner.os }}-${{ hashFiles('poetry.lock') }}
      
      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --no-root
      
      - name: Google Cloud SQL Proxy
        uses: NewNepal-org/gce-cloudsql-proxy-action@master
        with:
          creds: ${{ secrets.GOOGLE_APPLICATION_CREDENTIALS }}
          instance: ${{ secrets.NGM_SQL_INSTANCE }} 
      
      - name: Run District Court scraper
        working-directory: ./ngm
        run: poetry run scrapy crawl district_court_cases
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
